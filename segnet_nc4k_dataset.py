# -*- coding: utf-8 -*-
"""SegNet_nc4k_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1klC84i-iJCMLQsMNtafb_avd1YYPTex6
"""

import torch

print(torch.__version__)
print(torch.cuda.is_available())
if torch.cuda.is_available():
    print(torch.cuda.get_device_name(0))
else:
    print("CUDA not available. Running on CPU.")

from google.colab import drive
drive.mount('/content/drive')

!unzip "/content/drive/MyDrive/nc4k.zip" -d /content/nc4k

import os
print("Extracted folders:", os.listdir('/content/nc4k'))

dataset_path = '/content/nc4k'

def get_nc4k_folders(base_path):
    return {
        'images': f'{base_path}/Imgs',
        'gt_masks': f'{base_path}/GT',
        'instances': f'{base_path}/Instance'  # Optional for instance segmentation
    }

nc4k_folders = get_nc4k_folders(dataset_path)

def count_files(folder_dict):
    for key, folder in folder_dict.items():
        if os.path.exists(folder):
            print(f"{key}: {len(os.listdir(folder))} files")
        else:
            print(f"{key}: Folder not found")

print("NC4K Dataset:")
count_files(nc4k_folders)

import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import glob

class NC4KDataset(Dataset):
    def __init__(self, img_dir, mask_dir, transform=None, mask_transform=None):
        self.img_dir = img_dir
        self.mask_dir = mask_dir

        # Get all image files
        self.image_files = sorted(glob.glob(os.path.join(img_dir, '*')))
        self.transform = transform
        self.mask_transform = mask_transform

        # Filter images that have corresponding masks
        self.valid_pairs = []
        for img_path in self.image_files:
            img_name = os.path.basename(img_path)
            # Try different mask extensions
            mask_name = img_name.replace('.jpg', '.png').replace('.jpeg', '.png')
            mask_path = os.path.join(mask_dir, mask_name)

            if os.path.exists(mask_path):
                self.valid_pairs.append((img_path, mask_path))

        print(f"Found {len(self.valid_pairs)} valid image-mask pairs")

    def __len__(self):
        return len(self.valid_pairs)

    def __getitem__(self, idx):
        img_path, mask_path = self.valid_pairs[idx]

        # Load image and mask
        image = Image.open(img_path).convert('RGB')
        mask = Image.open(mask_path).convert('L')

        if self.transform:
            image = self.transform(image)
        if self.mask_transform:
            mask = self.mask_transform(mask)

        return image, mask

# Data transforms
transform = transforms.Compose([
    transforms.Resize((352, 352)),  # Common size for COD tasks
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

mask_transform = transforms.Compose([
    transforms.Resize((352, 352)),
    transforms.ToTensor()
])

# Create full dataset
full_dataset = NC4KDataset(
    img_dir=nc4k_folders['images'],
    mask_dir=nc4k_folders['gt_masks'],
    transform=transform,
    mask_transform=mask_transform
)

# Split dataset: 70% train, 20% val, 10% test
from torch.utils.data import random_split

total_size = len(full_dataset)
train_size = int(0.7 * total_size)
val_size = int(0.2 * total_size)
test_size = total_size - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(
    full_dataset,
    [train_size, val_size, test_size],
    generator=torch.Generator().manual_seed(42)  # For reproducibility
)

# Create dataloaders
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)

# Print dataset statistics
print(f"\nDataset Split:")
print(f"Total samples: {total_size}")
print(f"Training samples: {len(train_dataset)}")
print(f"Validation samples: {len(val_dataset)}")
print(f"Test samples: {len(test_dataset)}")

# Test data loading
try:
    images, masks = next(iter(train_loader))
    print(f"\nBatch shapes:")
    print(f"Image batch shape: {images.shape}")
    print(f"Mask batch shape: {masks.shape}")
    print(f"Image value range: [{images.min():.3f}, {images.max():.3f}]")
    print(f"Mask value range: [{masks.min():.3f}, {masks.max():.3f}]")
except Exception as e:
    print(f"Error loading data: {e}")

import matplotlib.pyplot as plt
import torch

def visualize_samples(dataset, num_samples=50):
    for idx in range(num_samples):
        image, mask = dataset[idx]

        # Denormalize image for visualization if normalized
        if image.max() <= 1:
            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
            image = image * std + mean
            image = torch.clamp(image, 0, 1)

        fig, axes = plt.subplots(1, 2, figsize=(4,4))
        axes[0].imshow(image.permute(1, 2, 0))
        axes[0].set_title('Image')
        axes[0].axis('off')

        axes[1].imshow(mask.squeeze(), cmap='gray')
        axes[1].set_title('Ground Truth Mask')
        axes[1].axis('off')

        plt.tight_layout()
        plt.show()

# Print (show) 5 sample images and masks
visualize_samples(full_dataset, num_samples=50)

import torch
import torch.nn as nn
import torch.nn.functional as F

class SimpleSegNet(nn.Module):
    def __init__(self, in_channels=3, out_channels=1):
        super(SimpleSegNet, self).__init__()
        # Encoder
        self.enc1 = nn.Sequential(
            nn.Conv2d(in_channels, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True)
        )
        self.pool1 = nn.MaxPool2d(2, 2, return_indices=True)
        self.enc2 = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True)
        )
        self.pool2 = nn.MaxPool2d(2, 2, return_indices=True)

        # Decoder
        self.unpool2 = nn.MaxUnpool2d(2, 2)
        self.dec2 = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True)
        )
        self.unpool1 = nn.MaxUnpool2d(2, 2)
        self.dec1 = nn.Conv2d(64, out_channels, 3, padding=1)

    def forward(self, x):
        # Encoder
        x1 = self.enc1(x)
        x1p, idx1 = self.pool1(x1)
        x2 = self.enc2(x1p)
        x2p, idx2 = self.pool2(x2)
        # Decoder
        x = self.unpool2(x2p, idx2, output_size=x2.size())
        x = self.dec2(x)
        x = self.unpool1(x, idx1, output_size=x1.size())
        x = self.dec1(x)
        return x  # logits, use sigmoid in loss/metrics

# Instantiate model
model = SimpleSegNet(in_channels=3, out_channels=1)

import torch
import torch.nn as nn
import torch.optim as optim

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = SimpleSegNet(in_channels=3, out_channels=1).to(device)
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)

num_epochs = 60

for epoch in range(num_epochs):
    # Training phase
    model.train()
    train_loss = 0.0
    for images, masks in train_loader:
        images, masks = images.to(device), masks.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * images.size(0)
    train_loss /= len(train_loader.dataset)

    # Validation phase
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for images, masks in val_loader:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            loss = criterion(outputs, masks)
            val_loss += loss.item() * images.size(0)
    val_loss /= len(val_loader.dataset)

    print(f"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")

# Testing phase (after training)
model.eval()
test_loss = 0.0
with torch.no_grad():
    for images, masks in test_loader:
        images, masks = images.to(device), masks.to(device)
        outputs = model(images)
        loss = criterion(outputs, masks)
        test_loss += loss.item() * images.size(0)
test_loss /= len(test_loader.dataset)
print(f"Test Loss: {test_loss:.4f}")



import numpy as np
import matplotlib.pyplot as plt

def visualize_in_batches(model, loader, device, batch_size=32, images_per_row=8):
    model.eval()
    # ImageNet mean and std for denormalization
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    for batch_idx, (images, _) in enumerate(loader):
        with torch.no_grad():
            images = images.to(device)
            outputs = model(images)
            probs = torch.sigmoid(outputs).cpu().numpy()

        num_images = images.shape[0]
        rows = int(np.ceil(num_images / images_per_row))

        plt.figure(figsize=(2.5*images_per_row, 2.5*rows))
        for idx in range(num_images):
            img = images[idx].cpu().permute(1, 2, 0).numpy()
            # Denormalize and clip
            img = img * std + mean
            img = np.clip(img, 0, 1)

            prob_map = probs[idx].squeeze()

            plt.subplot(rows, images_per_row*2, 2*idx+1)
            plt.imshow(img)
            plt.axis('off')

            plt.subplot(rows, images_per_row*2, 2*idx+2)
            plt.imshow(img)
            plt.imshow(prob_map, cmap='jet', alpha=0.5)
            plt.axis('off')

        plt.tight_layout()
        plt.suptitle(f'Batch {batch_idx+1}', y=1.02)
        plt.show()
        plt.close()
visualize_in_batches(model, test_loader, device, batch_size=32, images_per_row=8)